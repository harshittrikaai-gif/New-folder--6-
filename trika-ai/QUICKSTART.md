# ğŸš€ Quick Start Guide - OpenAI Integration

## 30 Second Setup

### 1ï¸âƒ£ Backend
```bash
cd backend
pip install -r requirements.txt
# Edit .env and add your OpenAI API key
OPENAI_API_KEY=sk-your-key-here
# Start the server
uvicorn main:app --reload
```

### 2ï¸âƒ£ Frontend
```bash
cd frontend
npm install
npm run dev
```

### 3ï¸âƒ£ Chat!
- Open http://localhost:3000
- Go to Chat page
- Send a message
- âœ… You'll see streaming responses from OpenAI!

---

## What Just Happened?

You now have a full-stack AI chat application with:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Frontend (Next.js)                     â”‚
â”‚  â€¢ Real-time chat UI                    â”‚
â”‚  â€¢ Supports file upload                 â”‚
â”‚  â€¢ Conversation history                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
        REST API with Server-Sent Events
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Backend (FastAPI)                      â”‚
â”‚  â€¢ OpenAI API integration                â”‚
â”‚  â€¢ Message persistence                  â”‚
â”‚  â€¢ RAG support (optional)                â”‚
â”‚  â€¢ Async streaming                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI gpt-4-turbo-preview             â”‚
â”‚  â€¢ Real-time text generation            â”‚
â”‚  â€¢ Token streaming                      â”‚
â”‚  â€¢ Memory of conversation                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Changes

**File Modified**: `backend/app/engine/agents.py`
- Simplified `stream_response()` method
- Direct OpenAI API streaming via `ChatOpenAI.astream()`
- Better error handling

**Key Feature**: All messages are saved to database automatically

## Test It

```bash
# Run the integration test
cd backend
python test_openai_integration.py
```

Expected output:
```
ğŸš€ Testing Chat Stream...
ğŸ“¥ Streaming Response:
Paris is the capital of France...
âœ… Conversation ID: {conversation-id}
```

## Common Commands

```bash
# Start backend with auto-reload
uvicorn main:app --reload

# Start frontend with hot reload  
npm run dev

# Run tests
python test_openai_integration.py

# Format Python code
black app/

# Run type checking
mypy app/
```

## Environment Variables

Create `backend/.env`:
```env
OPENAI_API_KEY=sk-your-key-here
OPENAI_MODEL=gpt-4-turbo-preview
DEBUG=false
```

## Example API Call

```bash
curl -X POST http://localhost:8000/api/v1/chat/ \
  -H "Content-Type: application/json" \
  -d '{
    "message": "What is the capital of France?",
    "stream": true
  }'
```

Response (Server-Sent Events):
```
data: {"type": "content", "content": "Paris"}
data: {"type": "content", "content": " is the capital"}
data: {"type": "content", "content": " of France."}
data: {"type": "done", "conversation_id": "abc-123"}
```

## What's Included

âœ… OpenAI API integration with streaming
âœ… Conversation history in database
âœ… Multi-turn conversations
âœ… Error handling with fallbacks
âœ… Support for multiple models
âœ… Real-time frontend updates
âœ… Comprehensive test suite
âœ… Full documentation

## Troubleshooting

| Issue | Solution |
|-------|----------|
| "Invalid API Key" | Check OPENAI_API_KEY in .env |
| Connection refused | Ensure backend runs on port 8000 |
| Slow responses | Normal first time, check API rate limits |
| No streaming | Verify your OpenAI account has API access |

## Next Features

- [ ] Upload documents for RAG context
- [ ] Web search integration
- [ ] Custom system prompts
- [ ] Conversation branching
- [ ] Export conversations
- [ ] Rate limiting
- [ ] API cost tracking

## Support

For detailed setup: See [OPENAI_SETUP.md](OPENAI_SETUP.md)
For technical details: See [INTEGRATION_SUMMARY.md](INTEGRATION_SUMMARY.md)

---

**Status**: âœ… Production Ready
**Last Updated**: January 9, 2026
